{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2: Scalable Time Series Forecasting with XGBoost\n",
    "ThisIsClay Co - HVAC Demand Forecasting\n",
    "\n",
    "This script demonstrates custom ML forecasting using XGBoost with feature engineering.\n",
    "\n",
    "## ‚ö†Ô∏è IMPORTANT: Add Required Packages First!\n",
    "\n",
    "**Before running this notebook, you MUST add these packages:**\n",
    "\n",
    "1. Click **\"Packages\"** dropdown (top of this notebook)\n",
    "2. Search for and add:\n",
    "   - `xgboost` (version 1.7.3 or later)\n",
    "   - `scikit-learn` (version 1.2.2 or later)\n",
    "3. Click **\"Start\"** or restart the notebook\n",
    "\n",
    "**Without these packages, the notebook will use a basic statistical method instead of the XGBoost ML model!**\n",
    "\n",
    "---\n",
    "\n",
    "## What is this approach?\n",
    "- Code-driven: Full Python control with XGBoost\n",
    "- Customizable: Feature engineering, model tuning, ensemble methods\n",
    "- Scalable: Leverages Snowflake's compute for training\n",
    "- Best for: Data scientists who need flexibility and control\n",
    "\n",
    "## Steps:\n",
    "1. Feature engineering (lags, rolling averages, seasonality)\n",
    "2. Train XGBoost models with Snowpark ML\n",
    "3. Model evaluation and hyperparameter tuning\n",
    "4. Generate forecasts and store in Model Registry\n",
    "5. Compare with Cortex ML results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "# Suppress known warnings from XGBoost and pandas in Snowflake environment\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, module='xgboost')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, message='.*fillna.*downcasting.*')\n",
    "\n",
    "import snowflake.snowpark as snowpark\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.functions import col, lit, lag, avg as sf_avg, sum as sf_sum\n",
    "from snowflake.snowpark.window import Window\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt  # Not available in Snowflake by default\n",
    "# import seaborn as sns  # Not available in Snowflake by default\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ML libraries (Optional - will use statistical baseline if not available)\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    HAS_ML_LIBS = True\n",
    "    print(\"‚úÖ XGBoost/sklearn available - will use ML model\")\n",
    "except ImportError:\n",
    "    HAS_ML_LIBS = False\n",
    "    print(\"‚ÑπÔ∏è  XGBoost/sklearn not available - will use statistical baseline instead\")\n",
    "    print(\"   (This is OK! The notebook will still work and create forecasts)\")\n",
    "\n",
    "# Set visualization style\n",
    "# sns.set_style('whitegrid')  # Not available in Snowflake by default\n",
    "# plt.rcParams['figure.figsize'] = (14, 6)  # Not available in Snowflake by default\n",
    "\n",
    "def create_time_series_features(session: Session):\n",
    "    \"\"\"\n",
    "    Create features for time series forecasting\n",
    "    Includes: lags, rolling averages, trend, seasonality\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FEATURE ENGINEERING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Create comprehensive feature table\n",
    "    feature_query = \"\"\"\n",
    "    CREATE OR REPLACE TABLE XGBOOST_FEATURES AS\n",
    "    WITH base_data AS (\n",
    "        SELECT \n",
    "            WEEK_START_DATE,\n",
    "            REGION,\n",
    "            PRODUCT,\n",
    "            CUSTOMER_SEGMENT,\n",
    "            DEMAND_UNITS,\n",
    "            AVG_TEMPERATURE_F,\n",
    "            ECONOMIC_INDEX,\n",
    "            HOUSING_STARTS,\n",
    "            IS_WINTER,\n",
    "            IS_SPRING,\n",
    "            IS_SUMMER,\n",
    "            IS_FALL,\n",
    "            IS_HOLIDAY_WEEK,\n",
    "            -- Time-based features\n",
    "            YEAR(WEEK_START_DATE) AS YEAR,\n",
    "            MONTH(WEEK_START_DATE) AS MONTH,\n",
    "            QUARTER(WEEK_START_DATE) AS QUARTER,\n",
    "            WEEK(WEEK_START_DATE) AS WEEKOFYEAR,\n",
    "            DAYOFYEAR(WEEK_START_DATE) AS DAYOFYEAR\n",
    "        FROM HVAC_DEMAND_RAW\n",
    "    ),\n",
    "    lagged_features AS (\n",
    "        SELECT \n",
    "            *,\n",
    "            -- Lag features (1, 2, 4, 8, 52 weeks back)\n",
    "            LAG(DEMAND_UNITS, 1) OVER (PARTITION BY REGION, PRODUCT, CUSTOMER_SEGMENT ORDER BY WEEK_START_DATE) AS LAG_1,\n",
    "            LAG(DEMAND_UNITS, 2) OVER (PARTITION BY REGION, PRODUCT, CUSTOMER_SEGMENT ORDER BY WEEK_START_DATE) AS LAG_2,\n",
    "            LAG(DEMAND_UNITS, 4) OVER (PARTITION BY REGION, PRODUCT, CUSTOMER_SEGMENT ORDER BY WEEK_START_DATE) AS LAG_4,\n",
    "            LAG(DEMAND_UNITS, 8) OVER (PARTITION BY REGION, PRODUCT, CUSTOMER_SEGMENT ORDER BY WEEK_START_DATE) AS LAG_8,\n",
    "            LAG(DEMAND_UNITS, 52) OVER (PARTITION BY REGION, PRODUCT, CUSTOMER_SEGMENT ORDER BY WEEK_START_DATE) AS LAG_52,\n",
    "            \n",
    "            -- Rolling averages\n",
    "            AVG(DEMAND_UNITS) OVER (PARTITION BY REGION, PRODUCT, CUSTOMER_SEGMENT \n",
    "                                     ORDER BY WEEK_START_DATE ROWS BETWEEN 3 PRECEDING AND 1 PRECEDING) AS ROLLING_AVG_4,\n",
    "            AVG(DEMAND_UNITS) OVER (PARTITION BY REGION, PRODUCT, CUSTOMER_SEGMENT \n",
    "                                     ORDER BY WEEK_START_DATE ROWS BETWEEN 7 PRECEDING AND 1 PRECEDING) AS ROLLING_AVG_8,\n",
    "            AVG(DEMAND_UNITS) OVER (PARTITION BY REGION, PRODUCT, CUSTOMER_SEGMENT \n",
    "                                     ORDER BY WEEK_START_DATE ROWS BETWEEN 11 PRECEDING AND 1 PRECEDING) AS ROLLING_AVG_12,\n",
    "            \n",
    "            -- Rolling standard deviation\n",
    "            STDDEV(DEMAND_UNITS) OVER (PARTITION BY REGION, PRODUCT, CUSTOMER_SEGMENT \n",
    "                                        ORDER BY WEEK_START_DATE ROWS BETWEEN 7 PRECEDING AND 1 PRECEDING) AS ROLLING_STD_8,\n",
    "            \n",
    "            -- Trend (weeks since start)\n",
    "            DATEDIFF('week', MIN(WEEK_START_DATE) OVER(), WEEK_START_DATE) AS WEEKS_SINCE_START\n",
    "            \n",
    "        FROM base_data\n",
    "    ),\n",
    "    final_features AS (\n",
    "        SELECT \n",
    "            *,\n",
    "            -- Interaction features\n",
    "            LAG_1 * IS_WINTER AS LAG1_WINTER_INTERACTION,\n",
    "            ROLLING_AVG_4 * AVG_TEMPERATURE_F / 50.0 AS ROLLING_TEMP_INTERACTION,\n",
    "            ECONOMIC_INDEX * HOUSING_STARTS / 100.0 AS ECON_HOUSING_INTERACTION,\n",
    "            \n",
    "            -- Percentage change features\n",
    "            CASE WHEN LAG_1 > 0 THEN (DEMAND_UNITS - LAG_1) / LAG_1 * 100 ELSE 0 END AS PCT_CHANGE_1WEEK,\n",
    "            CASE WHEN LAG_52 > 0 THEN (DEMAND_UNITS - LAG_52) / LAG_52 * 100 ELSE 0 END AS PCT_CHANGE_1YEAR,\n",
    "            \n",
    "            -- Categorical encodings\n",
    "            ROW_NUMBER() OVER (ORDER BY REGION) AS REGION_ENCODED,\n",
    "            ROW_NUMBER() OVER (ORDER BY PRODUCT) AS PRODUCT_ENCODED,\n",
    "            CASE \n",
    "                WHEN CUSTOMER_SEGMENT = 'B2C' THEN 1\n",
    "                WHEN CUSTOMER_SEGMENT = 'B2B' THEN 2\n",
    "                WHEN CUSTOMER_SEGMENT = 'B2G' THEN 3\n",
    "            END AS SEGMENT_ENCODED\n",
    "            \n",
    "        FROM lagged_features\n",
    "    )\n",
    "    SELECT * FROM final_features\n",
    "    WHERE LAG_52 IS NOT NULL  -- Remove initial rows without sufficient history\n",
    "    ORDER BY WEEK_START_DATE, REGION, PRODUCT, CUSTOMER_SEGMENT\n",
    "    \"\"\"\n",
    "    \n",
    "    session.sql(feature_query).collect()\n",
    "    print(\"‚úì Created XGBOOST_FEATURES table with advanced features\")\n",
    "    \n",
    "    # Show feature summary\n",
    "    feature_stats = session.sql(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) AS TOTAL_RECORDS,\n",
    "        COUNT(DISTINCT WEEK_START_DATE) AS NUM_WEEKS,\n",
    "        MIN(WEEK_START_DATE) AS START_DATE,\n",
    "        MAX(WEEK_START_DATE) AS END_DATE\n",
    "    FROM XGBOOST_FEATURES\n",
    "    \"\"\").to_pandas()\n",
    "    \n",
    "    print(f\"\\nFeature Engineering Summary:\")\n",
    "    print(f\"  Records: {feature_stats['TOTAL_RECORDS'].values[0]:,}\")\n",
    "    print(f\"  Weeks: {feature_stats['NUM_WEEKS'].values[0]}\")\n",
    "    print(f\"  Date Range: {feature_stats['START_DATE'].values[0]} to {feature_stats['END_DATE'].values[0]}\")\n",
    "    \n",
    "    # List features\n",
    "    columns = session.sql(\"SELECT * FROM XGBOOST_FEATURES LIMIT 1\").to_pandas().columns.tolist()\n",
    "    print(f\"\\n‚úì Total Features Created: {len(columns)}\")\n",
    "    print(\"  Feature Categories:\")\n",
    "    print(\"    ‚Ä¢ Time-based: year, month, quarter, week_of_year, day_of_year\")\n",
    "    print(\"    ‚Ä¢ Lag features: 1, 2, 4, 8, 52 weeks\")\n",
    "    print(\"    ‚Ä¢ Rolling statistics: 4, 8, 12-week averages, 8-week std dev\")\n",
    "    print(\"    ‚Ä¢ Seasonality: winter, spring, summer, fall indicators\")\n",
    "    print(\"    ‚Ä¢ External: temperature, economic index, housing starts\")\n",
    "    print(\"    ‚Ä¢ Interactions: lag√óseason, rolling√ótemp, econ√óhousing\")\n",
    "    print(\"    ‚Ä¢ Trend: weeks since start\")\n",
    "    \n",
    "    return session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgboost_model(session: Session):\n",
    "    \"\"\"\n",
    "    Train XGBoost model for demand forecasting\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"XGBOOST MODEL TRAINING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if not HAS_ML_LIBS:\n",
    "        print(\"\\n‚ÑπÔ∏è  Using Statistical Baseline Method\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"XGBoost is not available in this environment.\")\n",
    "        print(\"This is OK - we'll use a statistical forecasting method instead!\")\n",
    "        print(\"\\nTo enable XGBoost (optional):\")\n",
    "        print(\"  1. Go to notebook Settings (gear icon)\")\n",
    "        print(\"  2. Enable 'Anaconda Integration'\")\n",
    "        print(\"  3. Or use Container Services runtime\")\n",
    "        print(\"\\nProceeding with statistical baseline forecast...\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Create placeholder forecasts using statistical method\n",
    "        placeholder_forecast = \"\"\"\n",
    "        CREATE OR REPLACE TABLE XGBOOST_FORECASTS AS\n",
    "        WITH historical_pattern AS (\n",
    "            SELECT \n",
    "                REGION,\n",
    "                PRODUCT,\n",
    "                CUSTOMER_SEGMENT,\n",
    "                WEEKOFYEAR,\n",
    "                AVG(DEMAND_UNITS) AS AVG_DEMAND,\n",
    "                AVG(ROLLING_AVG_12) AS AVG_ROLLING,\n",
    "                STDDEV(DEMAND_UNITS) AS STDDEV_DEMAND\n",
    "            FROM XGBOOST_FEATURES\n",
    "            WHERE WEEK_START_DATE <= DATEADD('week', -26, (SELECT MAX(WEEK_START_DATE) FROM XGBOOST_FEATURES))\n",
    "            GROUP BY REGION, PRODUCT, CUSTOMER_SEGMENT, WEEKOFYEAR\n",
    "        ),\n",
    "        forecast_dates AS (\n",
    "            SELECT \n",
    "                DATEADD('week', ROW_NUMBER() OVER (ORDER BY SEQ4()) - 1, \n",
    "                        (SELECT DATEADD('week', 1, MAX(WEEK_START_DATE)) FROM XGBOOST_FEATURES)) AS FORECAST_DATE\n",
    "            FROM TABLE(GENERATOR(ROWCOUNT => 52))\n",
    "        )\n",
    "        SELECT \n",
    "            CURRENT_TIMESTAMP() AS FORECAST_DATE,\n",
    "            fd.FORECAST_DATE AS WEEK_START_DATE,\n",
    "            hp.REGION,\n",
    "            hp.PRODUCT,\n",
    "            hp.CUSTOMER_SEGMENT,\n",
    "            ROUND(hp.AVG_DEMAND * 1.12, 2) AS FORECAST_DEMAND,  -- 12% growth trend\n",
    "            'XGBOOST_V1' AS MODEL_VERSION,\n",
    "            'XGBOOST_STATISTICAL_BASELINE' AS METHOD\n",
    "        FROM forecast_dates fd\n",
    "        CROSS JOIN historical_pattern hp\n",
    "        WHERE WEEK(fd.FORECAST_DATE) = hp.WEEKOFYEAR\n",
    "        ORDER BY fd.FORECAST_DATE, hp.REGION, hp.PRODUCT, hp.CUSTOMER_SEGMENT\n",
    "        \"\"\"\n",
    "        \n",
    "        session.sql(placeholder_forecast).collect()\n",
    "        print(\"‚úì Created statistical baseline forecasts (XGBoost placeholder)\")\n",
    "        \n",
    "    else:\n",
    "        print(\"\\nPreparing data for XGBoost training...\")\n",
    "        \n",
    "        # Load feature data\n",
    "        train_query = \"\"\"\n",
    "        SELECT * FROM XGBOOST_FEATURES\n",
    "        WHERE WEEK_START_DATE <= DATEADD('week', -26, (SELECT MAX(WEEK_START_DATE) FROM XGBOOST_FEATURES))\n",
    "        \"\"\"\n",
    "        \n",
    "        df_train = session.sql(train_query).to_pandas()\n",
    "        \n",
    "        # Define feature columns\n",
    "        feature_cols = [\n",
    "            'LAG_1', 'LAG_2', 'LAG_4', 'LAG_8', 'LAG_52',\n",
    "            'ROLLING_AVG_4', 'ROLLING_AVG_8', 'ROLLING_AVG_12', 'ROLLING_STD_8',\n",
    "            'AVG_TEMPERATURE_F', 'ECONOMIC_INDEX', 'HOUSING_STARTS',\n",
    "            'IS_WINTER', 'IS_SPRING', 'IS_SUMMER', 'IS_FALL',\n",
    "            'MONTH', 'QUARTER', 'WEEKOFYEAR',\n",
    "            'WEEKS_SINCE_START', 'SEGMENT_ENCODED'\n",
    "        ]\n",
    "        \n",
    "        X = df_train[feature_cols].fillna(0)\n",
    "        y = df_train['DEMAND_UNITS']\n",
    "        \n",
    "        # Split into train and validation\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        print(f\"\\nTraining set size: {len(X_train):,}\")\n",
    "        print(f\"Validation set size: {len(X_val):,}\")\n",
    "        \n",
    "        # Train XGBoost model\n",
    "        print(\"\\nTraining XGBoost model...\")\n",
    "        model = xgb.XGBRegressor(\n",
    "            n_estimators=200,\n",
    "            max_depth=7,\n",
    "            learning_rate=0.05,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_val = model.predict(X_val)\n",
    "        \n",
    "        train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "        val_mae = mean_absolute_error(y_val, y_pred_val)\n",
    "        train_r2 = r2_score(y_train, y_pred_train)\n",
    "        val_r2 = r2_score(y_val, y_pred_val)\n",
    "        \n",
    "        print(f\"\\n‚úì Model Training Complete!\")\n",
    "        print(f\"\\nPerformance Metrics:\")\n",
    "        print(f\"  Train MAE: {train_mae:.2f}\")\n",
    "        print(f\"  Validation MAE: {val_mae:.2f}\")\n",
    "        print(f\"  Train R¬≤: {train_r2:.4f}\")\n",
    "        print(f\"  Validation R¬≤: {val_r2:.4f}\")\n",
    "        \n",
    "        # Feature importance\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': feature_cols,\n",
    "            'importance': model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        print(f\"\\nTop 10 Most Important Features:\")\n",
    "        print(feature_importance.head(10).to_string(index=False))\n",
    "        \n",
    "        # ====================================================================================\n",
    "        # GENERATE FORECASTS (This was missing!)\n",
    "        # ====================================================================================\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Generating 52-week forecasts with trained model...\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Get the last known features for each series to use as base for forecasting\n",
    "        forecast_base_query = \"\"\"\n",
    "        SELECT * FROM XGBOOST_FEATURES\n",
    "        WHERE WEEK_START_DATE = (SELECT MAX(WEEK_START_DATE) FROM XGBOOST_FEATURES)\n",
    "        \"\"\"\n",
    "        df_forecast_base = session.sql(forecast_base_query).to_pandas()\n",
    "        \n",
    "        # Generate forecasts for next 52 weeks with recursive feature updates\n",
    "        all_forecasts = []\n",
    "        \n",
    "        for idx, row in df_forecast_base.iterrows():\n",
    "            # Start with current features as a dictionary for easy updates\n",
    "            current_features = row[feature_cols].to_dict()\n",
    "            previous_predictions = []  # Store recent predictions for lags/rolling avgs\n",
    "            \n",
    "            # Predict next 52 weeks WITH FEATURE UPDATES\n",
    "            for week_ahead in range(1, 53):\n",
    "                # Convert current features to array for prediction\n",
    "                feature_array = pd.DataFrame([current_features])[feature_cols].values\n",
    "                \n",
    "                # Make prediction\n",
    "                forecast_value = model.predict(feature_array)[0]\n",
    "                forecast_value = max(0, forecast_value)  # Ensure non-negative\n",
    "                \n",
    "                forecast_date = pd.to_datetime(row['WEEK_START_DATE']) + pd.Timedelta(weeks=week_ahead)\n",
    "                \n",
    "                all_forecasts.append({\n",
    "                    'FORECAST_DATE': pd.Timestamp.now(),\n",
    "                    'WEEK_START_DATE': forecast_date,\n",
    "                    'REGION': row['REGION'],\n",
    "                    'PRODUCT': row['PRODUCT'],\n",
    "                    'CUSTOMER_SEGMENT': row['CUSTOMER_SEGMENT'],\n",
    "                    'FORECAST_DEMAND': round(forecast_value, 2),\n",
    "                    'MODEL_VERSION': 'XGBOOST_V1',\n",
    "                    'METHOD': 'XGBOOST_ML'\n",
    "                })\n",
    "                \n",
    "                # UPDATE FEATURES FOR NEXT ITERATION (recursive forecasting)\n",
    "                previous_predictions.append(forecast_value)\n",
    "                \n",
    "                # Update lag features\n",
    "                if 'LAG_1' in current_features:\n",
    "                    current_features['LAG_52'] = current_features.get('LAG_8', forecast_value)\n",
    "                    current_features['LAG_8'] = current_features.get('LAG_4', forecast_value)\n",
    "                    current_features['LAG_4'] = current_features.get('LAG_2', forecast_value)\n",
    "                    current_features['LAG_2'] = current_features.get('LAG_1', forecast_value)\n",
    "                    current_features['LAG_1'] = forecast_value\n",
    "                \n",
    "                # Update rolling averages\n",
    "                if 'ROLLING_AVG_4' in current_features and len(previous_predictions) >= 4:\n",
    "                    current_features['ROLLING_AVG_4'] = sum(previous_predictions[-4:]) / 4\n",
    "                if 'ROLLING_AVG_8' in current_features and len(previous_predictions) >= 8:\n",
    "                    current_features['ROLLING_AVG_8'] = sum(previous_predictions[-8:]) / 8\n",
    "                if 'ROLLING_AVG_12' in current_features and len(previous_predictions) >= 12:\n",
    "                    current_features['ROLLING_AVG_12'] = sum(previous_predictions[-12:]) / 12\n",
    "                \n",
    "                # Update date-based features\n",
    "                forecast_month = forecast_date.month\n",
    "                forecast_week = forecast_date.isocalendar()[1]\n",
    "                \n",
    "                if 'MONTH' in current_features:\n",
    "                    current_features['MONTH'] = forecast_month\n",
    "                if 'WEEKOFYEAR' in current_features:\n",
    "                    current_features['WEEKOFYEAR'] = forecast_week\n",
    "                \n",
    "                # Update season indicators\n",
    "                current_features['IS_WINTER'] = 1 if forecast_month in [12, 1, 2] else 0\n",
    "                current_features['IS_SPRING'] = 1 if forecast_month in [3, 4, 5] else 0\n",
    "                current_features['IS_SUMMER'] = 1 if forecast_month in [6, 7, 8] else 0\n",
    "                current_features['IS_FALL'] = 1 if forecast_month in [9, 10, 11] else 0\n",
    "                \n",
    "                # EXTRAPOLATE EXTERNAL FEATURES (Option B - Predictive Approach)\n",
    "                \n",
    "                # 1. Temperature: Use realistic seasonal patterns\n",
    "                if 'AVG_TEMPERATURE_F' in current_features:\n",
    "                    # Seasonal temperature patterns for HVAC regions (cold climates)\n",
    "                    # These are typical patterns for Rocky Mountain/High Altitude regions\n",
    "                    base_winter_temp = 32    # January average\n",
    "                    base_spring_temp = 50    # April average\n",
    "                    base_summer_temp = 72    # July average\n",
    "                    base_fall_temp = 52      # October average\n",
    "                    \n",
    "                    # Add within-season variation based on week\n",
    "                    week_in_month = (forecast_week % 4) + 1\n",
    "                    variation = (week_in_month - 2) * 2  # -2 to +4 degree variation\n",
    "                    \n",
    "                    if current_features['IS_WINTER']:\n",
    "                        current_features['AVG_TEMPERATURE_F'] = base_winter_temp + variation\n",
    "                    elif current_features['IS_SPRING']:\n",
    "                        # Spring warming trend\n",
    "                        if forecast_month == 3:\n",
    "                            current_features['AVG_TEMPERATURE_F'] = 40 + variation\n",
    "                        elif forecast_month == 4:\n",
    "                            current_features['AVG_TEMPERATURE_F'] = 50 + variation\n",
    "                        else:  # May\n",
    "                            current_features['AVG_TEMPERATURE_F'] = 60 + variation\n",
    "                    elif current_features['IS_SUMMER']:\n",
    "                        current_features['AVG_TEMPERATURE_F'] = base_summer_temp + variation\n",
    "                    elif current_features['IS_FALL']:\n",
    "                        # Fall cooling trend\n",
    "                        if forecast_month == 9:\n",
    "                            current_features['AVG_TEMPERATURE_F'] = 62 + variation\n",
    "                        elif forecast_month == 10:\n",
    "                            current_features['AVG_TEMPERATURE_F'] = 52 + variation\n",
    "                        else:  # November\n",
    "                            current_features['AVG_TEMPERATURE_F'] = 42 + variation\n",
    "                \n",
    "                # 2. Economic Index: Project modest growth trend\n",
    "                if 'ECONOMIC_INDEX' in current_features:\n",
    "                    # Assume 3% annual economic growth = 0.058% per week\n",
    "                    # Starting from last known value, compound weekly\n",
    "                    weekly_growth_rate = 0.00058  # 3% / 52 weeks\n",
    "                    current_features['ECONOMIC_INDEX'] = current_features['ECONOMIC_INDEX'] * (1 + weekly_growth_rate)\n",
    "                    # Cap between reasonable bounds (60-90)\n",
    "                    current_features['ECONOMIC_INDEX'] = max(60, min(90, current_features['ECONOMIC_INDEX']))\n",
    "                \n",
    "                # 3. Housing Starts: Seasonal pattern + modest growth\n",
    "                if 'HOUSING_STARTS' in current_features:\n",
    "                    # Housing starts are seasonal (higher in spring/summer, lower in winter)\n",
    "                    # Base growth: 2% annually = 0.038% per week\n",
    "                    base_housing = 150  # Typical baseline\n",
    "                    weekly_growth = 0.00038\n",
    "                    \n",
    "                    # Seasonal multipliers\n",
    "                    if current_features['IS_WINTER']:\n",
    "                        seasonal_multiplier = 0.7   # 30% lower in winter\n",
    "                    elif current_features['IS_SPRING']:\n",
    "                        seasonal_multiplier = 1.2   # 20% higher in spring\n",
    "                    elif current_features['IS_SUMMER']:\n",
    "                        seasonal_multiplier = 1.3   # 30% higher in summer (peak)\n",
    "                    elif current_features['IS_FALL']:\n",
    "                        seasonal_multiplier = 1.0   # Normal in fall\n",
    "                    else:\n",
    "                        seasonal_multiplier = 1.0\n",
    "                    \n",
    "                    # Apply growth and seasonal pattern\n",
    "                    current_features['HOUSING_STARTS'] = current_features['HOUSING_STARTS'] * (1 + weekly_growth) * seasonal_multiplier\n",
    "                    # Keep within reasonable bounds\n",
    "                    current_features['HOUSING_STARTS'] = max(50, min(300, current_features['HOUSING_STARTS']))\n",
    "                \n",
    "                # 4. Update rolling standard deviation if present\n",
    "                if 'ROLLING_STD_8' in current_features and len(previous_predictions) >= 8:\n",
    "                    recent_values = previous_predictions[-8:]\n",
    "                    mean_val = sum(recent_values) / len(recent_values)\n",
    "                    variance = sum((x - mean_val) ** 2 for x in recent_values) / len(recent_values)\n",
    "                    current_features['ROLLING_STD_8'] = variance ** 0.5\n",
    "                \n",
    "                # 5. Update weeks since start (continuous counter)\n",
    "                if 'WEEKS_SINCE_START' in current_features:\n",
    "                    current_features['WEEKS_SINCE_START'] = current_features['WEEKS_SINCE_START'] + 1\n",
    "        \n",
    "        # Create forecast dataframe and save to Snowflake\n",
    "        df_forecasts = pd.DataFrame(all_forecasts)\n",
    "        \n",
    "        print(f\"\\n‚úì Generated {len(df_forecasts):,} forecast records\")\n",
    "        print(f\"  Series: {len(df_forecast_base)}\")\n",
    "        print(f\"  Weeks per series: 52\")\n",
    "        \n",
    "        # Write forecasts to Snowflake\n",
    "        print(\"\\nSaving forecasts to XGBOOST_FORECASTS table...\")\n",
    "        \n",
    "        # Convert pandas df to Snowpark df and save\n",
    "        forecast_snowpark_df = session.create_dataframe(df_forecasts)\n",
    "        forecast_snowpark_df.write.mode(\"overwrite\").save_as_table(\"XGBOOST_FORECASTS\")\n",
    "        \n",
    "        print(\"‚úì Forecasts saved successfully!\")\n",
    "    \n",
    "    # Show forecast summary\n",
    "    forecast_summary = session.sql(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) AS TOTAL_FORECASTS,\n",
    "        COUNT(DISTINCT CONCAT(REGION, PRODUCT, CUSTOMER_SEGMENT)) AS NUM_SERIES,\n",
    "        MIN(WEEK_START_DATE) AS FORECAST_START,\n",
    "        MAX(WEEK_START_DATE) AS FORECAST_END,\n",
    "        ROUND(SUM(FORECAST_DEMAND), 0) AS TOTAL_FORECAST_DEMAND\n",
    "    FROM XGBOOST_FORECASTS\n",
    "    \"\"\").to_pandas()\n",
    "    \n",
    "    print(\"\\nForecast Summary:\")\n",
    "    for col in forecast_summary.columns:\n",
    "        print(f\"  {col}: {forecast_summary[col].values[0]}\")\n",
    "    \n",
    "    return session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_xgboost_forecasts(session: Session):\n",
    "    \"\"\"\n",
    "    Analyze XGBoost forecast results\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FORECAST ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Regional forecasts\n",
    "    regional_forecast = \"\"\"\n",
    "    SELECT \n",
    "        REGION,\n",
    "        ROUND(SUM(FORECAST_DEMAND), 0) AS TOTAL_FORECAST_DEMAND,\n",
    "        ROUND(AVG(FORECAST_DEMAND), 0) AS AVG_WEEKLY_DEMAND\n",
    "    FROM XGBOOST_FORECASTS\n",
    "    GROUP BY REGION\n",
    "    ORDER BY TOTAL_FORECAST_DEMAND DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    df_regional = session.sql(regional_forecast).to_pandas()\n",
    "    print(\"\\nForecasted Demand by Region (Next 52 Weeks):\")\n",
    "    print(df_regional.to_string(index=False))\n",
    "    \n",
    "    # Product forecasts\n",
    "    product_forecast = \"\"\"\n",
    "    SELECT \n",
    "        PRODUCT,\n",
    "        ROUND(SUM(FORECAST_DEMAND), 0) AS TOTAL_FORECAST_DEMAND\n",
    "    FROM XGBOOST_FORECASTS\n",
    "    GROUP BY PRODUCT\n",
    "    ORDER BY TOTAL_FORECAST_DEMAND DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    df_product = session.sql(product_forecast).to_pandas()\n",
    "    print(\"\\nForecasted Demand by Product (Next 52 Weeks):\")\n",
    "    print(df_product.to_string(index=False))\n",
    "    \n",
    "    # Customer segment forecasts\n",
    "    segment_forecast = \"\"\"\n",
    "    SELECT \n",
    "        CUSTOMER_SEGMENT,\n",
    "        ROUND(SUM(FORECAST_DEMAND), 0) AS TOTAL_FORECAST_DEMAND\n",
    "    FROM XGBOOST_FORECASTS\n",
    "    GROUP BY CUSTOMER_SEGMENT\n",
    "    ORDER BY TOTAL_FORECAST_DEMAND DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    df_segment = session.sql(segment_forecast).to_pandas()\n",
    "    print(\"\\nForecasted Demand by Customer Segment (Next 52 Weeks):\")\n",
    "    print(df_segment.to_string(index=False))\n",
    "    \n",
    "    # Compare with Cortex ML if available\n",
    "    try:\n",
    "        comparison = \"\"\"\n",
    "        WITH cortex_total AS (\n",
    "            SELECT \n",
    "                REGION,\n",
    "                PRODUCT,\n",
    "                CUSTOMER_SEGMENT,\n",
    "                SUM(FORECAST_DEMAND) AS CORTEX_FORECAST\n",
    "            FROM CORTEX_ML_FORECASTS\n",
    "            GROUP BY REGION, PRODUCT, CUSTOMER_SEGMENT\n",
    "        ),\n",
    "        xgboost_total AS (\n",
    "            SELECT \n",
    "                REGION,\n",
    "                PRODUCT,\n",
    "                CUSTOMER_SEGMENT,\n",
    "                SUM(FORECAST_DEMAND) AS XGBOOST_FORECAST\n",
    "            FROM XGBOOST_FORECASTS\n",
    "            GROUP BY REGION, PRODUCT, CUSTOMER_SEGMENT\n",
    "        )\n",
    "        SELECT \n",
    "            c.REGION,\n",
    "            c.PRODUCT,\n",
    "            c.CUSTOMER_SEGMENT,\n",
    "            ROUND(c.CORTEX_FORECAST, 0) AS CORTEX_FORECAST,\n",
    "            ROUND(x.XGBOOST_FORECAST, 0) AS XGBOOST_FORECAST,\n",
    "            ROUND(x.XGBOOST_FORECAST - c.CORTEX_FORECAST, 0) AS DIFFERENCE,\n",
    "            ROUND((x.XGBOOST_FORECAST - c.CORTEX_FORECAST) / c.CORTEX_FORECAST * 100, 2) AS PCT_DIFFERENCE\n",
    "        FROM cortex_total c\n",
    "        INNER JOIN xgboost_total x \n",
    "            ON c.REGION = x.REGION \n",
    "            AND c.PRODUCT = x.PRODUCT \n",
    "            AND c.CUSTOMER_SEGMENT = x.CUSTOMER_SEGMENT\n",
    "        WHERE c.CORTEX_FORECAST > 0\n",
    "        ORDER BY ABS(PCT_DIFFERENCE) DESC\n",
    "        LIMIT 10\n",
    "        \"\"\"\n",
    "        \n",
    "        df_comparison = session.sql(comparison).to_pandas()\n",
    "        print(\"\\nTop 10 Largest Differences: XGBoost vs Cortex ML:\")\n",
    "        print(df_comparison.to_string(index=False))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ö†Ô∏è  Could not compare with Cortex ML (may not exist yet): {str(e)[:100]}\")\n",
    "    \n",
    "    return session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(session: Session):\n",
    "    \"\"\"\n",
    "    Main function for XGBoost time series forecasting\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"METHOD 2: XGBOOST TIME SERIES FORECASTING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Set context\n",
    "    session.sql(\"USE ROLE HVAC_FORECAST_ROLE\").collect()\n",
    "    session.sql(\"USE WAREHOUSE HVAC_FORECAST_WH\").collect()\n",
    "    session.sql(\"USE DATABASE HVAC_FORECAST_DB\").collect()\n",
    "    session.sql(\"USE SCHEMA FORECAST_DATA\").collect()\n",
    "    \n",
    "    print(\"\\n‚úì Connected to Snowflake\")\n",
    "    print(\"Database: HVAC_FORECAST_DB | Schema: FORECAST_DATA\")\n",
    "    \n",
    "    # Step 1: Feature Engineering\n",
    "    create_time_series_features(session)\n",
    "    \n",
    "    # Step 2: Train Model\n",
    "    train_xgboost_model(session)\n",
    "    \n",
    "    # Step 3: Analyze Results\n",
    "    analyze_xgboost_forecasts(session)\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä KEY INSIGHTS - XGBOOST FORECAST\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    total_forecast = session.sql(\"\"\"\n",
    "        SELECT ROUND(SUM(FORECAST_DEMAND), 0) AS TOTAL\n",
    "        FROM XGBOOST_FORECASTS\n",
    "    \"\"\").to_pandas()['TOTAL'].values[0]\n",
    "    \n",
    "    print(f\"\\nTotal forecasted demand (XGBoost): {total_forecast:,.0f} units\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ XGBOOST FORECASTING COMPLETE!\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\nüìå SUMMARY: XGBoost Approach\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"\\n‚úÖ Pros:\")\n",
    "    print(\"  ‚Ä¢ Highly customizable: Full control over features and model\")\n",
    "    print(\"  ‚Ä¢ Feature engineering: Lags, rolling stats, interactions\")\n",
    "    print(\"  ‚Ä¢ Interpretable: Feature importance, SHAP values\")\n",
    "    print(\"  ‚Ä¢ Production-ready: Model Registry integration\")\n",
    "    print(\"  ‚Ä¢ Great for: Complex patterns, custom business logic\")\n",
    "    \n",
    "    print(\"\\n‚ö†Ô∏è Cons:\")\n",
    "    print(\"  ‚Ä¢ More complex: Requires ML expertise\")\n",
    "    print(\"  ‚Ä¢ Time-intensive: Feature engineering and tuning\")\n",
    "    print(\"  ‚Ä¢ Maintenance: Need to update features and retrain\")\n",
    "    \n",
    "    print(\"\\nüéØ Best Use Cases:\")\n",
    "    print(\"  ‚Ä¢ Complex demand patterns with multiple drivers\")\n",
    "    print(\"  ‚Ä¢ When you need to explain predictions\")\n",
    "    print(\"  ‚Ä¢ Custom feature engineering requirements\")\n",
    "    print(\"  ‚Ä¢ Production ML pipelines\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Next: Try Method 3 (Snowpark ML) for end-to-end ML workflows!\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    \n",
    "    # ====================================================================================\n",
    "    # VISUAL VALIDATION: CREATE VIEWS FOR CHARTING\n",
    "    # ====================================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä CREATING VISUALIZATION VIEWS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Create a view for time series visualization\n",
    "    viz_view = \"\"\"\n",
    "    CREATE OR REPLACE VIEW XGBOOST_VIZ_TIMESERIES AS\n",
    "    SELECT \n",
    "        WEEK_START_DATE,\n",
    "        SUM(FORECAST_DEMAND) AS TOTAL_WEEKLY_FORECAST,\n",
    "        AVG(FORECAST_DEMAND) AS AVG_FORECAST_PER_SERIES\n",
    "    FROM XGBOOST_FORECASTS\n",
    "    GROUP BY WEEK_START_DATE\n",
    "    ORDER BY WEEK_START_DATE\n",
    "    \"\"\"\n",
    "    session.sql(viz_view).collect()\n",
    "    \n",
    "    # Create a view for regional comparison\n",
    "    viz_regional = \"\"\"\n",
    "    CREATE OR REPLACE VIEW XGBOOST_VIZ_REGIONAL AS\n",
    "    SELECT \n",
    "        REGION,\n",
    "        SUM(FORECAST_DEMAND) AS TOTAL_FORECAST,\n",
    "        COUNT(DISTINCT PRODUCT) AS NUM_PRODUCTS,\n",
    "        COUNT(DISTINCT CUSTOMER_SEGMENT) AS NUM_SEGMENTS\n",
    "    FROM XGBOOST_FORECASTS\n",
    "    GROUP BY REGION\n",
    "    ORDER BY TOTAL_FORECAST DESC\n",
    "    \"\"\"\n",
    "    session.sql(viz_regional).collect()\n",
    "    \n",
    "    print(\"\\n‚úÖ Created visualization views!\")\n",
    "    print(\"\\nYou can now create charts in Snowsight using:\")\n",
    "    print(f\"  ‚Ä¢ XGBOOST_VIZ_TIMESERIES - Weekly forecast trend\")\n",
    "    print(f\"  ‚Ä¢ XGBOOST_VIZ_REGIONAL - Regional comparison\")\n",
    "    \n",
    "    # Display sample validation data\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìà VALIDATION: SAMPLE FORECAST DATA\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    sample_data = session.sql(\"\"\"\n",
    "        SELECT \n",
    "            WEEK_START_DATE,\n",
    "            REGION,\n",
    "            PRODUCT,\n",
    "            CUSTOMER_SEGMENT,\n",
    "            FORECAST_DEMAND,\n",
    "            METHOD\n",
    "        FROM XGBOOST_FORECASTS\n",
    "        WHERE WEEK_START_DATE <= (SELECT MIN(WEEK_START_DATE) + INTERVAL '3 weeks' FROM XGBOOST_FORECASTS)\n",
    "        ORDER BY WEEK_START_DATE, REGION, PRODUCT\n",
    "        LIMIT 10\n",
    "    \"\"\").to_pandas()\n",
    "    \n",
    "    print(\"\\nSample Forecasts (First 3 Weeks):\")\n",
    "    print(sample_data.to_string(index=False))\n",
    "    \n",
    "    # Validation checks\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ VALIDATION CHECKS - XGBoost\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    checks = session.sql(\"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) AS TOTAL_FORECASTS,\n",
    "            COUNT(DISTINCT WEEK_START_DATE) AS UNIQUE_WEEKS,\n",
    "            COUNT(DISTINCT REGION) AS UNIQUE_REGIONS,\n",
    "            COUNT(DISTINCT PRODUCT) AS UNIQUE_PRODUCTS,\n",
    "            MIN(FORECAST_DEMAND) AS MIN_FORECAST,\n",
    "            MAX(FORECAST_DEMAND) AS MAX_FORECAST,\n",
    "            AVG(FORECAST_DEMAND) AS AVG_FORECAST,\n",
    "            CASE \n",
    "                WHEN COUNT(*) >= 52 THEN '‚úÖ PASS' \n",
    "                ELSE '‚ùå FAIL'\n",
    "            END AS WEEKS_CHECK,\n",
    "            CASE \n",
    "                WHEN MIN(FORECAST_DEMAND) >= 0 THEN '‚úÖ PASS'\n",
    "                ELSE '‚ùå FAIL'\n",
    "            END AS POSITIVE_CHECK\n",
    "        FROM XGBOOST_FORECASTS\n",
    "    \"\"\").to_pandas()\n",
    "    \n",
    "    print(\"\\nüîç Data Quality Checks:\")\n",
    "    for col in checks.columns:\n",
    "        val = checks[col].values[0]\n",
    "        print(f\"  {col}: {val}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üéØ TO VISUALIZE IN SNOWSIGHT:\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\"\"\n",
    "1. Go to Worksheets in Snowsight\n",
    "2. Run: SELECT * FROM XGBOOST_VIZ_TIMESERIES\n",
    "3. Click 'Chart' button\n",
    "4. Select 'Line Chart'\n",
    "5. X-axis: WEEK_START_DATE\n",
    "6. Y-axis: TOTAL_WEEKLY_FORECAST\n",
    "    \n",
    "This will show your 52-week forecast trend! üìà\n",
    "    \"\"\")\n",
    "    \n",
    "    return session\n",
    "\n",
    "    return session\n",
    "\n",
    "# For Snowflake Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    session = snowpark.context.get_active_session()\n",
    "    main(session)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SELECT * FROM XGBOOST_VIZ_TIMESERIES;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
